

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/jg-square.png">
  <link rel="icon" href="/img/jg.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="jin">
  <meta name="keywords" content="">
  
    <meta name="description" content="自编码器 (AE), 变分自编码器 (VAE), 去噪自编码器 (DAE), 向量量化变分自编码器 (VQVAE).">
<meta property="og:type" content="article">
<meta property="og:title" content="生成模型基础 | 1 自编码器">
<meta property="og:url" content="https://disembo.github.io/Note/Course/gen-models/1/index.html">
<meta property="og:site_name" content="Jin&#39;s Blog">
<meta property="og:description" content="自编码器 (AE), 变分自编码器 (VAE), 去噪自编码器 (DAE), 向量量化变分自编码器 (VQVAE).">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-ae.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-ae-bottleneck.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-vae.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-vae-discontinuous.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-vae-reparameterization.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-dae.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-dae-mask.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-vqvae.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-vqvae-multihead.png">
<meta property="article:published_time" content="2025-09-23T14:00:00.000Z">
<meta property="article:modified_time" content="2025-11-04T05:38:47.464Z">
<meta property="article:author" content="jin">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-ae.png">
  
  
    <meta name="referrer" content="no-referrer-when-downgrade">
  
  
  <title>生成模型基础 | 1 自编码器 | Jin&#39;s Blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/additional.css">
<link rel="stylesheet" href="/css/html-hint.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"disembo.github.io","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":"#"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":3},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<!-- hexo injector head_end start --><script src="/js/mathjax-cfg.js"></script><script async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Jin&#39;s Blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>Links</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="生成模型基础 | 1 自编码器"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-09-23 22:00" pubdate>
          2025年9月23日 晚上
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    

    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">生成模型基础 | 1 自编码器</h1>
            
            
              <div class="markdown-body">
                
                <html><head></head><body>
<p>现今火热的 ChatGPT, Gemini, Stable Diffusion 等等都是生成模型.
生成模型是很神奇的东西, 它似乎可以 “无中生有”,
源源不断地生出五花八门的图片、文章、视频……</p>
<p>什么是生成模型? 考虑一个随机数发生器, 它可以生成出服从 <span class="math inline">\([0,1]\)</span> 上某个分布 <span class="math inline">\(p(x)\)</span> 的伪随机数. 它具体是怎么做的呢?
首先它会生成 <span class="math inline">\([0,1]\)</span>
上服从均匀分布的伪随机数 <span class="math inline">\(z\)</span>
(通过线性同余等方法); 然后通过一个映射 <span class="math inline">\(f:[0,1]\to[0,1]\)</span> 将 <span class="math inline">\(z\)</span> 映到服从分布 <span class="math inline">\(p(x)\)</span> 的伪随机数 <span class="math inline">\(x=f(z)\)</span> (其中 <span class="math inline">\(f=F^{-1}\)</span>, 而 <span class="math inline">\(F\)</span> 是 <span class="math inline">\(p(x)\)</span> 的累积分布函数).</p>
<p>换言之, 随机数发生器是将随机噪声 (如 <span class="math inline">\([0,1]\)</span> 上的均匀分布随机数)
映射到服从某一分布的随机变量 (比如服从 <span class="math inline">\(p(x)\)</span> 的随机数) 的东西. <strong>生成模型
(generative model)</strong> 也是如此. 它将随机噪声映射为
(服从特定分布的) 语句、图片、三维形状等 (称为样本).</p>
<p>然而, 生成模型并没有随机数发生器那么简单:</p>
<ul>
<li>样本的真实分布 <span class="math inline">\(p(x)\)</span> 是未知的,
我们不能通过简单的公式 <span class="math inline">\(x=F^{-1}(z)\)</span>
生成 <span class="math inline">\(x\)</span>.
<ul>
<li>需要利用样本集 <span class="math inline">\(\{x_i\}_i\)</span>
训练生成模型, 让它自己学会样本的分布.</li>
</ul></li>
<li>样本 <span class="math inline">\(x\in\R^N\)</span> 的维数很高,
直接生成样本的计算代价很大.
<ul>
<li>需要一些方法处理稀疏性.</li>
</ul></li>
<li>……</li>
</ul>
<h2 id="autoencoders">1  Autoencoders</h2>
<p>今天讲的是最简单的生成模型, 它如此简单以至于在 CPU 上就可以训练.
当然它的表现肯定不比如今的大模型,
但已经成为了绝大多数生成模型的一部分.</p>
<h3 id="basics">1.1  Basics</h3>
<p>一般来说, 高维空间 <span class="math inline">\({\cal X}\)</span>
(维数为 <span class="math inline">\(N\)</span>) 中的样本分布是很稀疏的
(比如所有 <span class="math inline">\(128\times128\)</span> 的图像中,
几乎所有图像都是噪声, 只有极少数是有意义的), 即 <span class="math inline">\(p\)</span> 的支集 <span class="math display">\[
\Sigma := \overline{ \{ x\in{\cal X} \mid p(x)&gt;0 \} }
\]</span> 是一个 <span class="math inline">\(K\)</span> 维子流形 (<span class="math inline">\(K\ll D\)</span>). <strong>自编码器 (autoencoder,
AE)</strong> 主要的作用是学习该子流形. AE 包含两部分:</p>
<ul>
<li>编码映射 (encoder) <span class="math inline">\(\varphi_\theta:{\cal
X}\to{\cal Z}\)</span> 将数据压缩到低维空间 <span class="math inline">\({\cal Z}=\R^D\)</span> (隐空间, latent space);
<ul>
<li>编码后的数据 <span class="math inline">\(\varphi_\theta(x)\)</span>
也称为隐变量 (latent) 或者表示 (representation).</li>
</ul></li>
<li>解码映射 (decoder) <span class="math inline">\(\psi_\theta:{\cal
Z}\to\mathcal{X}\)</span> 将压缩的数据还原.</li>
</ul>
<p><img src="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-ae.png" style="zoom:45%;" cloud-img="" lazyload="true"></p>
<p>一般 encoder 和 decoder 都是 MLP (参数为 <span class="math inline">\(\theta\)</span>), 它们组成了一个 bottleneck
的神经网络结构: 将输入 <span class="math inline">\(x\)</span>
压缩到低维空间, 再还原回去.</p>
<p><img src="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-ae-bottleneck.png" style="zoom:45%;" cloud-img="" lazyload="true"></p>
<p>我们希望压缩尽量是无损的, 即复合映射 <span class="math inline">\(\varphi_\theta\circ\psi_\theta\)</span> 在 <span class="math inline">\(\Sigma\)</span> 上接近恒等映射. 由此给出 <span class="math inline">\(\ell^2\)</span> 重建损失 (reconstruction loss)
<span class="math display">\[
\Align{
\mathcal{L}_{\textsf{recon}}
:={}&amp; \operatorname{E}_{x\sim p} \|
    (\psi_\theta \circ \varphi_\theta) (x) - x
\|_2^2.
}
\]</span> AE 的一些初步应用包括:</p>
<ul>
<li>将高维数据降维, 以便可视化.</li>
<li>数据压缩.</li>
<li>表示学习.</li>
</ul>
<p>AE 的 encoder 和 decoder 映射都应当足够简单,
防止过拟合或者拟合到恒等映射.</p>
<h3 id="linear-aes">1.2  Linear AEs</h3>
<p>最简单的 AE, 就是取 <span class="math inline">\(\varphi_\theta\)</span> 和 <span class="math inline">\(\psi_\theta\)</span> 都是线性映射,
为了方便分别记作 <span class="math inline">\(U,V\)</span>. 将输入数据集
<span class="math inline">\(\{x_n\}\)</span> (每条数据是一个列向量)
堆叠成一个矩阵 <span class="math inline">\(X\)</span>. 此时 AE
训练的优化目标为 <span class="math display">\[
\min_{U,V} \| VUX - X \|_2^2,
\]</span> 即主成分分析 (PCA).</p>
<h2 id="variational-autoencoders">2  Variational Autoencoders</h2>
<h3 id="a-naïve-vae">2.1  A naïve VAE</h3>
<p>AE 是否是一个生成模型? 考虑隐空间中数据的分布 <span class="math display">\[
\varphi_\theta(x) \sim (\varphi_\theta)_*p,
\qquad \textsf{其中}\; x\sim p,
\]</span> (其中 <span class="math inline">\((\varphi_\theta)_*p\)</span>
表示将概率分布 <span class="math inline">\(p\)</span> 推到 <span class="math inline">\(\mathcal{Z}\)</span> 上) 只要我们知道 <span class="math inline">\((\varphi_\theta)_*p\)</span> 就可以从中采样了.
但是在一般的 AE 训练过程中, 我们并不知道 <span class="math inline">\((\varphi_\theta)_*p\)</span> 究竟是什么,
甚至不知道它的性质.</p>
<p><strong>变分自编码器 (variational autoencoder, VAE)</strong>
做的就是对隐空间的概率分布 <span class="math inline">\((\varphi_\theta)_*p\)</span> 做了 “正则化”,
让它尽量接近一个已知的、好的分布——标准正态分布 <span class="math inline">\(\mathcal{N}(0,I)\)</span>.</p>
<p><img src="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-vae.png" style="zoom:45%;" cloud-img="" lazyload="true"></p>
<p>如此一来, 我们就可以从隐空间 <span class="math inline">\(\mathcal{Z}\)</span> 上的正态分布 <span class="math inline">\(\mathcal{N}(0,I)\)</span> 中采样 <span class="math inline">\(z\)</span>, 然后经过 decoder 就可以生成新的数据了:
<span class="math display">\[
\psi_\theta(z) \sim p.
\]</span></p>
<p>在具体实现上, 我们一般将 “采样” 这个步骤放到 encoder 里: encoder
<span class="math inline">\(\varphi_\theta\)</span>
首先估计正态分布的均值和方差 <span class="math inline">\((\mu,\Sigma)\)</span>, 然后再从该正态分布 <span class="math inline">\(\mathcal{N}(\mu,\Sigma)\)</span>
中采样一个样本作为输出的 <span class="math inline">\(z=\varphi_\theta(x)\)</span>. 换言之, encoder
<span class="math inline">\(\varphi_\theta\)</span>
并不是一个确定的函数, 而是一个随机函数 (stochastic function),
其输入是确定的 <span class="math inline">\(x\)</span>,
输出是服从某一分布的随机变量. 这种表示方法称为随机隐变量表示 (stochastic
latent representation).</p>
<p>最后, 如何让 encoder 输出的分布接近于标准正态分布? 答案是用 KL
散度作为 “正则化”: <span class="math display">\[
\mathcal{L}_{\textsf{reg}}
:= D_\textsf{KL}( \mathcal{N}(\mu,\Sigma) \parallel \mathcal{N}(0,I) ).
\]</span> VAE 的损失函数是重建损失与正则化的线性组合, <span class="math display">\[
\mathcal{L} :=
\mathcal{L}_{\textsf{recon}} + \lambda \mathcal{L}_{\textsf{reg}}.
\]</span></p>
<div class="note note-warning">
<p><u>Note</u> 如果不使用 KL 散度正则化会发生什么? 考虑一个极端的情况,
encoder 对于所有的样本 <span class="math inline">\(\{x_i\}\)</span>
输出的均值 <span class="math inline">\(\mu\)</span> 都不一样, 而方差
<span class="math inline">\(\Sigma\)</span> 接近 <span class="math inline">\(0\)</span>. 这意味着 encoder 学到了一个多点分布,
过拟合了.</p>
</div>
<div class="note note-success">
<p><u>Theorem</u> (两个正态分布的 KL 散度) 设 <span class="math inline">\(p,q\)</span> 分别为 <span class="math inline">\(n\)</span> 维正态分布 <span class="math inline">\(\mathcal{N}(\mu_p,\Sigma_p)\)</span> 和 <span class="math inline">\(\mathcal{N}(\mu_q,\Sigma_q)\)</span> 的密度函数,
则 KL 散度 <span class="math display">\[
D_{\textsf{KL}}(p\parallel q) = \frac12\bqty{
  \tr(\Sigma_q^{-1}\Sigma_p)
  + (\mu_p-\mu_q)\T\Sigma_q^{-1}(\mu_p-\mu_q)
  - \log\det(\Sigma_p\Sigma_q^{-1})
  - n
}.
\]</span></p>
<p>特别地, 若 <span class="math inline">\(q\)</span> 为标准正态分布
<span class="math inline">\(\mathcal{N}(0,I)\)</span>, 则 <span class="math display">\[
D_{\textsf{KL}}(p\parallel q) = \frac12\bqty{
  \tr(\Sigma_p)
  + \mu_p\T\mu_p
  - \log\det(\Sigma_p)
  - n
}.
\]</span></p>
</div>
<h3 id="the-reparameterization-trick">2.2  The reparameterization trick</h3>
<p>VAE 看起来好极了, 但是如果我们想要用梯度下降法训练一个 VAE,
就会发现一个致命问题——从正态分布 <span class="math inline">\(\mathcal{N}(\mu,\Sigma)\)</span>
中采样的过程是非连续的, 导致损失函数关于 encoder 的参数不可微.</p>
<p><img src="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-vae-discontinuous.png" style="zoom:40%;" cloud-img="" lazyload="true"></p>
<p>如上图, 问题的关键是 samle 步阻碍了梯度反向传播.
解决办法也很简单——只要把 sample 步挪到外面即可 (即重参数化技巧).
即先从标准正态分布采样 <span class="math inline">\(\varepsilon\sim\mathcal{N}(0,I)\)</span>, 然后根据
<span class="math inline">\((\mu,\Sigma)\)</span> 缩放: <span class="math display">\[
z = \sqrt{\Sigma}\cdot\varepsilon + \mu \sim \mathcal{N}(\mu,\Sigma).
\]</span> 此时计算图为</p>
<p><img src="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-vae-reparameterization.png" style="zoom:40%;" cloud-img="" lazyload="true"></p>
<p>其中 sample 被挪到了支路上, 梯度可以畅通地反向传播到 encoder
的参数了.</p>
<h3 id="a-probabilistic-view">2.3  A probabilistic view</h3>
<p>从几何上看, VAE 学习了高维空间中子流形的局部参数化, 把数据降维了.
下面我们理论地解释 VAE 为什么能用.</p>
<p>统计学中有所谓参数估计问题, 即假设样本服从某一特定分布 <span class="math inline">\(p(x)\)</span>, 其参数为 <span class="math inline">\(\lambda\)</span>. 我们的任务是根据样本的观测值
<span class="math inline">\(x\)</span> 估计分布参数 <span class="math inline">\(\lambda\)</span>. 一个常用方法是最大似然估计
(MLE).</p>
<p>训练 VAE 就好比一个参数估计问题, 只不过此时 <span class="math inline">\(p(x)\)</span> 并非由参数 <span class="math inline">\(\lambda\)</span> 指导生成, 而是由另一个分布 <span class="math inline">\(p(z)\)</span> 指导生成 (<span class="math inline">\(z\)</span> 就是隐变量):</p>
<ol type="1">
<li><p>首先, 从一个已知的、简单的<strong>先验分布</strong> <span class="math inline">\(p(z)\)</span> (比如标准正态分布 <span class="math inline">\(\mathcal{N}(0,I)\)</span>) 中采样一个隐变量 <span class="math inline">\(z\)</span>.</p></li>
<li><p>然后, 利用一个复杂的条件概率分布 <span class="math inline">\(p(x\mid z)\)</span> (即<strong>似然函数</strong>,
由 decoder 建模) 从隐变量 <span class="math inline">\(z\)</span>
生成数据 <span class="math inline">\(x\)</span>.</p></li>
<li><p>(MLE) 我们的目标是最大化数据的<strong>边缘似然</strong>
(或<strong>证据</strong>) <span class="math display">\[
p(x) = \int_{\R^n} p(x\mid z) p(z) \dd{z}.
\]</span></p></li>
</ol>
<p>这里一大难点是 <span class="math inline">\(p(x)\)</span> 没法算,
因为这个高维积分不好求. 解决办法是引入一个较简单的分布 <span class="math inline">\(q(z\mid x)\)</span> 来近似 (未知的)
<strong>后验分布</strong> <span class="math inline">\(p(z\mid
x)\)</span>. 分布 <span class="math inline">\(q(z\mid x)\)</span>
也称为<strong>近似后验分布</strong>, 由 encoder 建模.</p>
<p>从最大化边缘似然 (证据) 开始: <span class="math display">\[
\Align{
\log{p_\theta(x)}
&amp;= \log\!\pqty{ \int_{\R^n} p(x\mid z)p(z) \dd{z} } \\
&amp;= \log\!\pqty{ \int_{\R^n}
    \frac{p(x\mid z)p(z)}{q(z\mid x)} \cdot q(z\mid x) \dd{z} } \\
&amp;= \log\operatorname{E}_{q(z\mid x)}\!
    \bqty{\frac{p(x\mid z)p(z)}{q(z\mid x)}} \\
&amp;\geq \operatorname{E}_{q(z\mid x)}\!
    \bqty{ \log\frac{p(x\mid z)p(z)}{q(z\mid x)} },
}
\]</span> 其中最后一步使用了 Jensen 不等式, 注意到 <span class="math inline">\(\log\)</span> 是上凸函数.
最后一行称为<strong>证据下界 (ELBO, evidence lower bound)</strong>,
它是对数证据 <span class="math inline">\(\log{p(x)}\)</span> 的一个下界.
我们进一步将 ELBO 展开: <span class="math display">\[
\Align{
\log p(x)
&amp;\geq \operatorname{ELBO}(q) \\
&amp;= \operatorname{E}_{q(z\mid x)} \bigl[\log p(x\mid z)\bigr]
    - \operatorname{E}_{q(z\mid x)}\!
    \bqty{ \log\frac{q(z\mid x)}{p(z)} } \\
&amp;= \blue{- H( q(z\mid x),p(x\mid z) )}
    \purple{{}- D_{\textsf{KL}}(q(z\mid x)\parallel p(z))}
    \vphantom{\Bigl[} ,
}
\]</span> 其中第一项是负的交叉熵, 第二项是负的 KL 散度.</p>
<p>因为 ELBO 是边缘似然的下界, 我们只需最大化 ELBO 即可,
也就是最小化交叉熵和 KL 散度:</p>
<ul>
<li>当交叉熵项取最小值时, <span class="math inline">\(q(z\mid
x)\)</span> 与 <span class="math inline">\(p(x\mid z)\)</span>
分布相同,</li>
<li>KL 散度项其实就是 VAE 的正则化损失 (令 encoder
的输出尽量接近先验分布 <span class="math inline">\(p(z)\)</span>).</li>
</ul>
<p>因此, 交叉熵与 KL 散度项恰好分别对应了重建损失与正则化, 这就从概率
(最大似然估计) 的角度解释了 VAE 的工作原理.</p>
<h3 id="problems-in-vae">2.4  Problems in VAE</h3>
<ul>
<li><p>VAE usually cannot go deep (check David Wipf’s work).</p></li>
<li><p>The dimension of the latent code is sensitive (check David Wipf’s
work).</p></li>
<li><p>VAE cannot do density estimation, i.e., accurately calculating
<span class="math inline">\(p(x)\)</span>.</p></li>
<li><p>VAE is usually used as a component of a system, but not a
standalone model.</p></li>
</ul>
<div class="note note-warning">
<p><u>Note</u> 为什么 VAE 的网络不能太深?</p>
<p>强大的 decoder <span class="math inline">\(p_\theta(x\mid z)\)</span>
可以仅凭很少的信息 (甚至忽略 <span class="math inline">\(z\)</span>)
就能很好地完成重建任务, 即最小化交叉熵 <span class="math inline">\(H(q_\phi(z\mid x),p_\theta(x\mid z))\)</span>.
此时, 网络发现最小化 KL 散度 <span class="math inline">\(D_{\textsf{KL}}(q_\phi(z\mid x)\parallel
p(z))\)</span> 是更简单的优化路径.</p>
<p>因此 encoder <span class="math inline">\(q_\phi(z\mid x)\)</span>
会忽略输入 <span class="math inline">\(x\)</span>, 直接输出一个接近先验
<span class="math inline">\(\mathcal{N}(0, I)\)</span> 的分布,
导致隐变量 <span class="math inline">\(z\)</span> 失去了信息量,
无法捕获数据的有效特征, 模型退化. 这也称为后验崩塌 (posterior
collapse).</p>
</div>
<h2 id="denoising-autoencoders">3  Denoising Autoencoders</h2>
<p>VAE 根据输入数据生成了一个高斯噪声, 再从中采样,
这可以看作是在输入数据中加入了噪声.
我们不妨简化一下这个流程——直接在输入数据上加噪, 然后喂给 autoencoder,
让它重建原本的输入. 这就称为<strong>去噪自编码器 (DAE, denoising
autoencoder)</strong>.</p>
<p><img src="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-dae.png" style="zoom:40%;" cloud-img="" lazyload="true"></p>
<ul>
<li>DAE 不需要 bottleneck 设计,
因为将噪声还原为干净输入的过程显然高度不平凡, 不可能像 AE 那样,
可以用一个恒等映射糊弄过去. DAE 通常是一个很大很深的神经网络.</li>
<li>DAE 不区分 encoder 和 decoder, 因为它并不是做表示学习的.</li>
<li>与 AE 一样, DAE 的损失函数是重建损失.</li>
</ul>
<p>DAE 的加噪办法一般是 masking, 也就是把输入的 tokens 向量随机 mask
掉一些元素 (变成特定的 [MASK] token, 如下图<span class="hint--html hint--top hint--hoverable hint--rounded hint--autosize"><hcontent class="hint__content">来自 Kaiming He et al, <em>Masked Autoencoders are
Scalable Vision Learners</em>, CVPR 2022. 其中的 decoder 就是一个 DAE,
灰色的是 [MASK].</hcontent><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref" style="text-decoration: none;"><sup>[1]</sup></a></span>).
另一种办法是在输入上代数叠加一个随机噪声.</p>
<p><img src="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-dae-mask.png" style="zoom:40%;" cloud-img="" lazyload="true"></p>
<p>DAE is known as one of the most efficient pre-training
(self-supervised) methods:</p>
<ul>
<li>Can be used with ANY data type</li>
<li>Usually is not considered as generative model, although it can
generate the missing part of the data</li>
</ul>
<h2 id="vqvaes">4  VQVAEs</h2>
<p>VQVAE 在视觉-语言大模型中用得很多.</p>
<h3 id="quantization">4.1  Quantization</h3>
<p>AE 和 VAE 做的都是学习连续对象的连续表示
(即隐向量连续变化会使得生成结果也连续变化),
这在图像、视频、三维生成中很有用,
然而并非所有的数据都是连续的——比如自然语言中的 tokens,
它们是一个个分立的值 (categorial). 语言 tokens 和图像 latent
这一本质的不同, 使得视觉-语言大模型在实现上很困难.</p>
<p>为了解决这一问题, 人们提出了<strong>向量量化变分自编码器 (VQ-VAE,
vector-quantized VAE)</strong>, 将连续的变量编码为离散的 latent.</p>
<p><img src="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-vqvae.png" style="zoom:40%;" cloud-img="" lazyload="true"></p>
<p>VQVAE 的架构与 VAE 相似. 为了将连续的 latent 离散化, VQVAE 引入了一个
codebook (编码表). Codebook 是有限个向量的集合 <span class="math inline">\(\{e_i\}_{i=1}^K\subset\R^D\)</span>. Encoder
的输出 <span class="math inline">\(z_e(x)\)</span> 会与 codebook
中的向量分别计算距离, 最后选择距离最小的那个 code <span class="math inline">\(e_q\)</span> 作为 latent <span class="math inline">\(z_q(x)\)</span>. 用公式写出来就是 <span class="math display">\[
z_q(x) \equiv e_q := \argmin_{e_i}\, \| z_d(x) - e_i \|_2.
\]</span> 离散化的 latent <span class="math inline">\(z_q(x)\)</span>
会作为 decoder 的输入, 重建结果为 <span class="math inline">\(\psi(z_q(x))\)</span>. 考虑重建损失 <span class="math display">\[
\| x - \psi(z_q(x)) \|_2,
\]</span> 这里遇到了一个问题: <span class="math inline">\(z_q\)</span>
是 <span class="math inline">\(\argmin\)</span> 来的, 关于 <span class="math inline">\(z_d(x)\)</span> 不连续, 导致损失函数关于 encoder
的参数不可微.</p>
<h3 id="the-straight-through-estimator">4.2  The straight-through
estimator</h3>
<p>解决办法是用一种叫做 “straight-through estimator” 的近似手段.</p>
<div class="note note-secondary">
<p>假设不可微函数 <span class="math inline">\(f:\R^n\to\R^n\)</span>, ST
estimator 的操作为:</p>
<ul>
<li>前向传播, 不作任何改动, 输出 <span class="math inline">\(f(x)\)</span>.</li>
<li>反向传播, 认为 <span class="math inline">\(\partial f/\partial x
\approx \mathrm{id}_{\R^n}\)</span>,
相当于用一个最平凡的映射作为近似梯度, 让网络参数得以更新.</li>
</ul>
<p>比如, 假设有损失函数 <span class="math inline">\(\mathcal{L}=f(g(x))\)</span>, 则梯度近似为 <span class="math display">\[
\pdv{\mathcal{L}}{x}
= \pdv{f}{g} \pdv{g}{x}
\approx 1 \cdot  \pdv{g}{x}
= \pdv{g}{x}.
\]</span> 这等价于引入 “stop gradient” 操作: <span class="math display">\[
\mathcal{L}
= g(x) + \orange{\operatorname{StopGradient}}\bigl[f(g(x)) - g(x)\bigr],
\]</span></p>
<ul>
<li><p>正向传播时, <span class="math inline">\({\operatorname{StopGradient}}\)</span> 为恒等映射,
因此 <span class="math inline">\(\mathcal{L}=g(x)+[f(g(x))-g(x)]=f(g(x))\)</span>.</p></li>
<li><p>反向传播时, <span class="math inline">\({\operatorname{StopGradient}}\)</span>
的梯度恒为零, 因此 <span class="math display">\[
\pdv{\mathcal{L}}{x} = \pdv{g}{x} + 0 = \pdv{g}{x}.
\]</span> 这和上面的结果是一样的.</p></li>
</ul>
</div>
<p>总之, 我们引入 “stop gradient” 操作: <span class="math display">\[
\mathcal{L}_{\textsf{recon}} := \Bigl\|
    x - \psi\bigl( z_e +
    \orange{\operatorname{StopGradient}}(z_q - z_e) \bigr)
\Bigr\|.
\]</span></p>
<ul>
<li>正向传播时, 可以计算出正确的结果.</li>
<li>反向传播时, 损失关于 decoder 参数的梯度是正确的, 关于 encoder
参数的梯度是近似的 (相当于认为 codebook lookup 的梯度为恒等映射),
可以相对合理地更新 encoder 的参数.</li>
</ul>
<p>为了减少梯度近似的误差, VQVAE 还引入了 codebook loss.</p>
<h3 id="codebook-loss">4.3  Codebook loss</h3>
<p>引入 stop gradient 后, 我们发现损失函数关于 <span class="math inline">\(z_q\)</span> 的梯度恒为零, 也就是说 codebook
永远不会更新了, 这显然不太好. 为了让 codebook 能够更新, 同时为了拉近
<span class="math inline">\(z_q\)</span> 与 <span class="math inline">\(z_e\)</span> 的距离 (以减少梯度近似的误差),
我们引入另外两个损失:</p>
<ul>
<li><p>Codebook 损失, <span class="math display">\[
\mathcal{L}_{\textsf{codebook}}
:= \| z_q - \operatorname{StopGradient}(z_e) \|,
\]</span> 只会更新 <span class="math inline">\(z_q\)</span>, 让 codebook
被选中的向量靠近 encoder 的输出 <span class="math inline">\(z_e\)</span>.</p></li>
<li><p>Commitment 损失, <span class="math display">\[
\mathcal{L}_{\textsf{commitment}}
:= \| z_e(x) - \operatorname{StopGradient}(z_q) \|,
\]</span> 只会更新 <span class="math inline">\(z_e\)</span>, 让 encoder
的输出向 codebook 中的向量靠近.</p></li>
</ul>
<p>总损失是三个损失的和: <span class="math display">\[
\mathcal{L} :=
\mathcal{L}_{\textsf{recon}} +
\mathcal{L}_{\textsf{codebook}} +
\beta\mathcal{L}_{\textsf{commitment}}.
\]</span></p>
<h3 id="improving-capacity">4.4  Improving capacity</h3>
<p>一般令 VQVAE 的 codebook 容量 <span class="math inline">\(K=8192\)</span>, 那岂不是意味着它只能生成 <span class="math inline">\(8192\)</span> 种不同的结果?</p>
<p>一种解决办法是多头 (multi-head) 量化, 即一共构造 <span class="math inline">\(L\)</span> 个 codebooks, 把 encoder 输出的 <span class="math inline">\(z_e(x)\)</span> 平均切分成 <span class="math inline">\(L\)</span> 个子向量, 每个子向量算得一个最近邻
code, 在将这 <span class="math inline">\(L\)</span> 个 codes 拼起来,
作为 decoder 的输入.</p>
<p><img src="https://raw.githubusercontent.com/Disembo/blog-media/master/course/gen-models/1-vqvae-multihead.png" style="zoom:40%;" cloud-img="" lazyload="true"></p>
<p>多头量化可以实现输出结果种类的指数级增长——比如当 <span class="math inline">\(L=16\)</span> 时, 所有可能的生成结果有 <span class="math display">\[
K^L = 8192^{16} \approx 4.11\times10^{62}
\]</span> 这么多种!</p>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1"><p>来自 Kaiming He et al, <em>Masked Autoencoders are
Scalable Vision Learners</em>, CVPR 2022. 其中的 decoder 就是一个 DAE,
灰色的是 [MASK].<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body></html>
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/Note/" class="category-chain-item">Note</a>
  
  
    <span>></span>
    
  <a href="/categories/Note/Course/" class="category-chain-item">Course</a>
  
  

  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" class="print-no-link">#机器学习</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>生成模型基础 | 1 自编码器</div>
      <div>https://disembo.github.io/Note/Course/gen-models/1/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>jin</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年9月23日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/">
                  <span class="hint--top hint--rounded" aria-label="SA - 相同方式共享">
                    <i class="iconfont icon-sa"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/Note/Course/gen-models/2/" title="生成模型基础 | 2 Transformers">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">生成模型基础 | 2 Transformers</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/Note/Course/info-theory/final/" title="信息论 | 期末考试">
                        <span class="hidden-mobile">信息论 | 期末考试</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <script type="text/javascript">
    Fluid.utils.loadComments('#comments', function() {
      var light = 'github-light';
      var dark = 'github-dark';
      var schema = document.documentElement.getAttribute('data-user-color-scheme');
      if (schema === 'dark') {
        schema = dark;
      } else {
        schema = light;
      }
      window.UtterancesThemeLight = light;
      window.UtterancesThemeDark = dark;
      var s = document.createElement('script');
      s.setAttribute('src', 'https://utteranc.es/client.js');
      s.setAttribute('repo', 'Disembo/blog-comments');
      s.setAttribute('issue-term', 'pathname');
      
      s.setAttribute('label', 'utterances');
      
      s.setAttribute('theme', schema);
      s.setAttribute('crossorigin', 'anonymous');
      document.getElementById('comments').appendChild(s);
    })
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="busuanzi_container_site_pv" style="display: none">
        Views: 
        <span id="busuanzi_value_site_pv"></span>
        
      </span>
    
    
      <span id="busuanzi_container_site_uv" style="display: none">
        Visitors: 
        <span id="busuanzi_value_site_uv"></span>
        
      </span>
    
    
  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>

  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
